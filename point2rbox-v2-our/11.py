import os
import glob
import torch
import numpy as np
import mmcv
import cv2
import tempfile
from tqdm import tqdm
from mmengine import Config

# å°è¯•å¯¼å…¥æ¨ç†æ¥å£
try:
    from mmrotate.apis.inference import init_detector, inference_detector
except ImportError:
    from mmdet.apis import init_detector, inference_detector

from mmrotate.registry import VISUALIZERS
from mmrotate.utils import register_all_modules

# ========== è‡ªå®šä¹‰è°ƒè‰²æ¿ï¼ˆè‡³å°‘15ç§é¢œè‰²ï¼Œå¯¹åº”DOTA 15ä¸ªç±»åˆ«ï¼‰ ==========
def get_dota_palette(num_classes):
    """ç”Ÿæˆè¶³å¤Ÿé•¿åº¦çš„DOTAæ•°æ®é›†è°ƒè‰²æ¿"""
    # åŸºç¡€é¢œè‰²ï¼ˆ15ç§ï¼Œè¦†ç›–DOTAæ‰€æœ‰ç±»åˆ«ï¼‰
    base_palette = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255),
        (0, 255, 255), (128, 0, 0), (0, 128, 0), (0, 0, 128), (128, 128, 0),
        (128, 0, 128), (0, 128, 128), (64, 0, 0), (0, 64, 0), (0, 0, 64)
    ]
    # å¦‚æœç±»åˆ«æ•°è¶…è¿‡15ï¼Œå¾ªç¯æ‰©å±•è°ƒè‰²æ¿
    palette = []
    for i in range(num_classes):
        palette.append(base_palette[i % len(base_palette)])
    return palette

def verify_model_predictions_advanced(config_path, checkpoint_path, img_dir, out_dir, score_thr=0.05):
    """
    é«˜çº§è¯Šæ–­è„šæœ¬ï¼šè¯¦ç»†ç»Ÿè®¡é¢„æµ‹æ¡†çš„å‡ ä½•å±æ€§ï¼ˆå°ºå¯¸ã€æ¯”ä¾‹ã€è§’åº¦ï¼‰ï¼Œç¡®ä¿æ¡†å’Œæ ‡ç­¾åŒæ—¶æ˜¾ç¤ºã€‚
    """
    register_all_modules()

    if not os.path.exists(out_dir):
        os.makedirs(out_dir)

    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {config_path}")
    try:
        model = init_detector(config_path, checkpoint_path, device='cuda:0')
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # ========== æ ¸å¿ƒï¼šDOTAå›ºå®š15ç±»ï¼Œé¿å…é…ç½®è·¯å¾„é”™è¯¯ ==========
    num_classes = 15
    # DOTAå®˜æ–¹ç±»åˆ«åˆ—è¡¨
    dota_classes = (
        'plane', 'baseball-diamond', 'bridge', 'ground-track-field',
        'small-vehicle', 'large-vehicle', 'ship', 'tennis-court',
        'basketball-court', 'storage-tank', 'soccer-ball-field', 'roundabout',
        'harbor', 'swimming-pool', 'helicopter'
    )
    class_names = dota_classes

    # å¯é€‰ï¼šå°è¯•ä»é…ç½®æ–‡ä»¶è‡ªåŠ¨è¯»å–ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    try:
        cfg = Config.fromfile(config_path)
        # å°è¯•å¸¸è§çš„ç±»åˆ«æ•°é…ç½®è·¯å¾„
        if hasattr(cfg.model, 'bbox_head'):
            auto_num_classes = cfg.model.bbox_head.num_classes
        elif hasattr(cfg.model, 'head'):
            auto_num_classes = cfg.model.head.num_classes
        elif hasattr(cfg.model, 'roi_head'):
            auto_num_classes = cfg.model.roi_head.bbox_head.num_classes
        else:
            auto_num_classes = num_classes
        
        if auto_num_classes != num_classes:
            print(f"è­¦å‘Šï¼šé…ç½®æ–‡ä»¶ä¸­ç±»åˆ«æ•°({auto_num_classes})ä¸DOTAæ ‡å‡†ç±»åˆ«æ•°(15)ä¸ä¸€è‡´ï¼")
            print(f"å°†ä½¿ç”¨DOTAæ ‡å‡†15ç±»è¿›è¡Œå¯è§†åŒ–")
    except Exception as e:
        print(f"ä»é…ç½®æ–‡ä»¶è¯»å–ç±»åˆ«æ•°å¤±è´¥: {e}ï¼Œä½¿ç”¨DOTAæ ‡å‡†15ç±»")

    # ========== æ ¸å¿ƒä¿®å¤ï¼šå¯è§†åŒ–å™¨åˆå§‹åŒ–ï¼ˆç§»é™¤é¡¶å±‚paletteå‚æ•°ï¼‰ ==========
    visualizer_cfg = dict(
        type='RotLocalVisualizer',
        name='visualizer',
        vis_backends=[{'type': 'LocalVisBackend', 'save_dir': out_dir}],
        line_width=2,
        # å…³é”®ä¿®å¤ï¼šç§»é™¤é¡¶å±‚paletteï¼Œä»…åœ¨dataset_metaä¸­æŒ‡å®š
        dataset_meta=dict(
            classes=class_names,
            palette=get_dota_palette(num_classes)  # paletteä»…æ”¾åœ¨dataset_metaä¸­
        )
    )
    visualizer = VISUALIZERS.build(visualizer_cfg)
    # å¼ºåˆ¶è¦†ç›–modelçš„dataset_metaï¼ˆç¡®ä¿ç±»åˆ«å’Œè°ƒè‰²æ¿ä¸€è‡´ï¼‰
    visualizer.dataset_meta = {
        'classes': class_names,
        'palette': get_dota_palette(num_classes)
    }

    # è·å–å›¾ç‰‡
    extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp']
    img_paths = []
    for ext in extensions:
        img_paths.extend(glob.glob(os.path.join(img_dir, ext)))
    img_paths.sort()
    
    if len(img_paths) == 0:
        print(f"é”™è¯¯: åœ¨ {img_dir} ä¸‹æœªæ‰¾åˆ°å›¾ç‰‡ã€‚")
        return

    print(f"æ‰¾åˆ° {len(img_paths)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹æ¨ç†å‰ 50 å¼ ...")
    
    # === æ•°æ®æ”¶é›†å®¹å™¨ ===
    stats = {
        'widths': [],
        'heights': [],
        'angles': [],
        'ratios': [],
        'scores': []
    }

    max_imgs = 50
    count_valid_imgs = 0

    for i, img_path in enumerate(tqdm(img_paths[:max_imgs])):
        img_name = os.path.basename(img_path)
        
        try:
            result = inference_detector(model, img_path)
        except Exception as e:
            print(f"æ¨ç†å¤±è´¥: {e}")
            continue
        
        pred_instances = result.pred_instances
        mask = pred_instances.scores > score_thr
        valid_bboxes = pred_instances.bboxes[mask]
        
        if len(valid_bboxes) > 0:
            count_valid_imgs += 1
            np_bboxes = valid_bboxes.detach().cpu().numpy()
            np_scores = pred_instances.scores[mask].detach().cpu().numpy()
            ws = np_bboxes[:, 2]
            hs = np_bboxes[:, 3]
            thetas = np_bboxes[:, 4]
            stats['widths'].extend(ws.tolist())
            stats['heights'].extend(hs.tolist())
            stats['scores'].extend(np_scores.tolist())
            stats['angles'].extend((thetas * 180 / np.pi).tolist())
            safe_ws = np.maximum(ws, 1e-6)
            safe_hs = np.maximum(hs, 1e-6)
            ratios = np.maximum(safe_ws / safe_hs, safe_hs / safe_ws)
            stats['ratios'].extend(ratios.tolist())

        # ========== æ¡†å’Œæ ‡ç­¾åŒæ—¶æ˜¾ç¤ºé€»è¾‘ ==========
        try:
            # 1. åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                tmp_path = tmp_file.name
            
            # 2. å¯è§†åŒ–å™¨ç»˜åˆ¶æ£€æµ‹æ¡†
            img = mmcv.imread(img_path)
            visualizer.add_datasample(
                name=img_name,
                image=mmcv.imconvert(img, 'bgr', 'rgb'),
                data_sample=result,
                draw_gt=False,
                draw_pred=True,
                show=False,
                out_file=tmp_path,
                pred_score_thr=score_thr
            )
            
            # 3. è¯»å–å¸¦æ¡†å›¾ç‰‡å¹¶åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            img_with_boxes = cv2.imread(tmp_path)
            os.remove(tmp_path)
            
            # 4. æå–æ ‡æ³¨ä¿¡æ¯
            pred_instances = result.pred_instances
            mask = pred_instances.scores > score_thr
            if mask.sum() == 0:
                cv2.imwrite(os.path.join(out_dir, img_name), img_with_boxes)
                continue
            
            valid_bboxes = pred_instances.bboxes[mask].detach().cpu().numpy()
            valid_scores = pred_instances.scores[mask].detach().cpu().numpy()
            valid_labels = pred_instances.labels[mask].detach().cpu().numpy()
            
            # 5. å åŠ æ ‡ç­¾åˆ°å›¾ç‰‡
            for bbox, score, label in zip(valid_bboxes, valid_scores, valid_labels):
                cx, cy, w, h, theta = bbox
                x_offset = -w/2 * np.cos(theta) - h/2 * np.sin(theta)
                y_offset = -w/2 * np.sin(theta) + h/2 * np.cos(theta)
                label_x = int(cx + x_offset)
                label_y = int(cy + y_offset)
                # é˜²æ­¢æ ‡ç­¾è¶…å‡ºå›¾ç‰‡è¾¹ç•Œ
                label_x = max(10, min(label_x, img_with_boxes.shape[1]-100))
                label_y = max(20, min(label_y, img_with_boxes.shape[0]-20))
                label_text = f"{class_names[label]} {score:.2f}"
                
                # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯å’Œæ–‡å­—
                (text_w, text_h), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                cv2.rectangle(
                    img_with_boxes, 
                    (label_x-2, label_y-text_h-4), 
                    (label_x+text_w+2, label_y+2), 
                    (0, 0, 0), 
                    -1
                )
                cv2.putText(
                    img_with_boxes,
                    label_text,
                    (label_x, label_y-2),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (255, 255, 255),
                    1
                )
            
            # 6. ä¿å­˜æœ€ç»ˆå›¾ç‰‡
            cv2.imwrite(os.path.join(out_dir, img_name), img_with_boxes)
            
        except Exception as e:
            print(f"å¯è§†åŒ–å¤±è´¥ {img_name}: {e}")

    # === è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š ===
    print("\n" + "="*60)
    print("ã€æ·±åº¦è¯Šæ–­æŠ¥å‘Šã€‘")
    num_boxes = len(stats['widths'])
    print(f"æ€»æ£€æµ‹æ¡†æ•°é‡: {num_boxes} (æ¥è‡ª {count_valid_imgs} å¼ å›¾ç‰‡)")

    if num_boxes > 0:
        def get_stats(data):
            return {
                'mean': np.mean(data),
                'min': np.min(data),
                'max': np.max(data),
                'median': np.median(data),
                'std': np.std(data)
            }

        w_s = get_stats(stats['widths'])
        h_s = get_stats(stats['heights'])
        a_s = get_stats(stats['angles'])
        r_s = get_stats(stats['ratios'])

        print("-" * 30)
        print(f"1. å°ºå¯¸ç»Ÿè®¡ (Pixels):")
        print(f"   å®½åº¦ (W): å‡å€¼={w_s['mean']:.1f}, ä¸­ä½æ•°={w_s['median']:.1f}, èŒƒå›´=[{w_s['min']:.1f}, {w_s['max']:.1f}]")
        print(f"   é«˜åº¦ (H): å‡å€¼={h_s['mean']:.1f}, ä¸­ä½æ•°={h_s['median']:.1f}, èŒƒå›´=[{h_s['min']:.1f}, {h_s['max']:.1f}]")
        
        print("-" * 30)
        print(f"2. å½¢çŠ¶åˆ†æ (é•¿å®½æ¯” Ratio = Max(W,H)/Min(W,H)):")
        print(f"   å‡å€¼ Ratio: {r_s['mean']:.1f}")
        print(f"   æœ€å¤§ Ratio: {r_s['max']:.1f}")
        print(f"   -> å¦‚æœ Ratio > 10ï¼Œè¯´æ˜æ˜¯â€œç»†é•¿æ¡â€")
        print(f"   -> å¦‚æœ Ratio > 100ï¼Œè¯´æ˜æ˜¯â€œæåº¦ç•¸å˜â€")

        print("-" * 30)
        print(f"3. è§’åº¦ç»Ÿè®¡ (Degrees):")
        print(f"   å‡å€¼: {a_s['mean']:.1f}Â°, æ ‡å‡†å·®: {a_s['std']:.1f}Â°")
        print(f"   -> å¦‚æœæ ‡å‡†å·®æ¥è¿‘ 0ï¼Œè¯´æ˜æ¨¡å‹å‘ç”Ÿäº†â€œè§’åº¦åå¡Œâ€ï¼Œåªä¼šè¾“å‡ºä¸€ä¸ªå›ºå®šè§’åº¦ã€‚")

        print("-" * 30)
        print("ã€æœ€ç»ˆç»“è®ºæ¨æ–­ã€‘")
        if w_s['mean'] > 2000 or h_s['mean'] > 2000:
            print("ğŸ”´ [å°ºå¯¸çˆ†ç‚¸] æ¨¡å‹æ­£åœ¨é¢„æµ‹å…¨å›¾å¤§å°çš„æ¡†ã€‚")
            print("   åŸå› ï¼šç¼ºä¹ loss_area æˆ– loss_overlapï¼Œæ¨¡å‹é€šè¿‡æœ€å¤§åŒ–é¢ç§¯æ¥è¦†ç›–ç‰©ä½“ã€‚")
        elif r_s['mean'] > 20:
            print("ğŸŸ  [æ¡çº¹ä¼ªå½±] æ¨¡å‹é¢„æµ‹å‡ºäº†æå…¶ç»†é•¿çš„æ¡çº¹ã€‚")
            print("   åŸå› ï¼šBox-Sensitive Loss åªæœ‰æ¨åŠ›æ²¡æœ‰æ‹‰åŠ›ï¼Œæ¨¡å‹æ‰¾åˆ°äº†â€œæ‰«æçº¿â€ä½œå¼Šè§£æ³•ã€‚")
        else:
            print("ğŸŸ¢ å°ºå¯¸åˆ†å¸ƒçœ‹èµ·æ¥ç›¸å¯¹æ­£å¸¸ï¼Œè¯·æ£€æŸ¥ IoU åŒ¹é…é—®é¢˜ã€‚")

    else:
        print("æœªæ£€æµ‹åˆ°ä»»ä½•æ¡†ã€‚")
    print("="*60)

if __name__ == '__main__':
    # ================= é…ç½®åŒºåŸŸ =================
    config_file = '/mnt/data/liurunxiang/workplace/point2rbox-v2-our/configs/point2rbox_v2/point2rbox_v2-1x-dota.py' 
    checkpoint_file = 'work_dirs/dt/1/e2e/epoch_1.pth'
    image_dir = '/mnt/data/xiekaikai/split_ss_dota/trainval/images'
    output_dir = '/mnt/data/liurunxiang/workplace/point2rbox-v2-our/work_dirs/dt/1/visual1'
    score_threshold = 0.5
    # ===========================================

    # å±è”½torch.meshgridæ— å…³è­¦å‘Š
    import warnings
    warnings.filterwarnings("ignore", message="torch.meshgrid: in an upcoming release")

    verify_model_predictions_advanced(config_file, checkpoint_file, image_dir, output_dir, score_threshold)