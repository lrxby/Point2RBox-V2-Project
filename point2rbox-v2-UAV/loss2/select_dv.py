import os
import glob
import numpy as np
import pandas as pd
from tqdm import tqdm
import multiprocessing

# ================= é…ç½®åŒºåŸŸ =================
# 1. æ•°æ®é›†æ ¹è·¯å¾„ (åŒ…å« trainã€valã€test æ–‡ä»¶å¤¹çš„ä¸Šçº§ç›®å½•)
DATASET_ROOT = '/mnt/data/xiekaikai/DroneVehicle'
# æŒ‡å®šéœ€è¦åˆå¹¶ç»Ÿè®¡çš„å­é›†
TARGET_SUBSETS = ['train', 'val', 'test']

# 2. è¿™é‡Œçš„å›¾åƒå°ºå¯¸ç”¨äº 'image-norm' (DOTA åˆ‡å›¾é€šå¸¸æ˜¯ 1024)
IMG_W, IMG_H = 1024, 1024

# 3. è¶…å‚æ•°æœç´¢ç©ºé—´ (Grid Search Space)
# (1) æ­£åˆ™åŒ–å¼ºåº¦: è¦†ç›–ä»æå°åˆ°è¾ƒå¤§çš„èŒƒå›´
LAMBDA_LIST = [1e-8, 1e-7, 1e-6, 1e-4, 1e-3, 0.01, 0.1, 1.0, 2, 3, 4, 5.0]

# (2) å½’ä¸€åŒ–æ–¹å¼: å¯¹æ¯” Z-Score å’Œ Image-Norm
NORM_TYPES = ['z-score', 'image-norm', 'none']

# (3) æ‹Ÿåˆå½¢å¼: å†æ¬¡ç¡®è®¤ Log æ˜¯å¦ç¨³åç¬¬ä¸€
MODES = ['log', 'linear', 'sqrt', 'square']

# 4. å…¶ä»–é…ç½®
CLASSES = ('car', 'bus', 'truck', 'van', 'freight_car')
EPS = 1e-6
WORKER_NUM = max(1, multiprocessing.cpu_count() - 4) # ç•™ç‚¹ä½™åœ°
MAX_FILES = None # è®¾ç½®ä¸º None åˆ™è·‘å…¨é‡æ•°æ®ï¼Œè®¾ç½®ä¸º 2000 å¯å¿«é€ŸéªŒè¯
# ===========================================

def polygon_area(coords):
    x = coords[0::2]
    y = coords[1::2]
    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))

def parse_txt(txt_path):
    """è§£æ DroneVehicle æ ¼å¼ LabelTxt æ–‡ä»¶"""
    bboxes = []
    labels = []
    try:
        with open(txt_path, 'r') as f:
            lines = f.readlines()
            for line in lines:
                parts = line.strip().split()
                if len(parts) < 9: continue
                
                # DroneVehicle æ ¼å¼: x1 y1 ... x4 y4 ç±»åˆ«ç´¢å¼•
                try:
                    cls_id = int(parts[8])  # ç¬¬9ä¸ªå­—æ®µæ˜¯ç±»åˆ«ç´¢å¼•
                except ValueError:
                    continue
                
                # è¿‡æ»¤éæ³•ç±»åˆ«ç´¢å¼•
                if cls_id < 0 or cls_id >= len(CLASSES):
                    continue
                cls_name = CLASSES[cls_id]  # è½¬æ¢ä¸ºç±»åˆ«åç§°ï¼ˆä¿æŒåç»­é€»è¾‘å…¼å®¹ï¼‰
                
                coords = list(map(float, parts[:8]))
                area = polygon_area(coords)
                if area <= 1: continue 
                
                s = np.sqrt(area)
                s = max(s, 1e-2)
                
                cx = sum(coords[0::2]) / 4.0
                cy = sum(coords[1::2]) / 4.0
                
                bboxes.append([cx, cy, s, s]) 
                labels.append(cls_name)
    except Exception:
        pass
    return np.array(bboxes), labels

def solve_perspective(bboxes, labels_str, mode, ridge_lambda, norm_type):
    """
    æ ¸å¿ƒè§£ç®—å™¨ï¼šé’ˆå¯¹ä¸€ç§ç‰¹å®šçš„å‚æ•°ç»„åˆè¿›è¡Œæ‹Ÿåˆå’Œè¯„ä¼°
    """
    N = len(bboxes)
    unique_labels = sorted(list(set(labels_str)))
    K = len(unique_labels)
    
    # çº¦æŸæ£€æŸ¥
    if N < K + 3: return None

    cls_to_idx = {name: i for i, name in enumerate(unique_labels)}
    labels_idx = np.array([cls_to_idx[name] for name in labels_str])

    # === 1. å‡†å¤‡æ•°æ® ===
    x_c = bboxes[:, 0]
    y_c = bboxes[:, 1]
    w = bboxes[:, 2] # w=s
    h = bboxes[:, 3] # h=s
    s_gt = np.sqrt(w * h)

    # === 2. ç›®æ ‡å˜é‡å˜æ¢ (Mode) ===
    if mode == 'log':
        Y = 0.5 * np.log(w * h)
    elif mode == 'linear':
        Y = s_gt
    elif mode == 'sqrt':
        Y = np.sqrt(s_gt)
    elif mode == 'square':
        Y = w * h

    # === 3. åæ ‡å½’ä¸€åŒ– (Norm Type) ===
    if norm_type == 'z-score':
        x_mean, x_std = np.mean(x_c), np.std(x_c)
        y_mean, y_std = np.mean(y_c), np.std(y_c)
        x_std = max(x_std, EPS)
        y_std = max(y_std, EPS)
        x_norm = (x_c - x_mean) / x_std
        y_norm = (y_c - y_mean) / y_std
        
    elif norm_type == 'image-norm':
        # æ˜ å°„åˆ° [-1, 1]
        x_norm = (x_c - IMG_W / 2.0) / (IMG_W / 2.0)
        y_norm = (y_c - IMG_H / 2.0) / (IMG_H / 2.0)
        
    else: # 'none'
        x_norm = x_c
        y_norm = y_c

    # === 4. æ„å»ºçŸ©é˜µä¸æ±‚è§£ ===
    A = np.zeros((N, 2 + K))
    A[:, 0] = x_norm
    A[:, 1] = y_norm
    for i, idx in enumerate(labels_idx):
        A[i, 2 + idx] = 1.0

    M = A.T @ A
    I_reg = np.eye(2 + K) * ridge_lambda # ä½¿ç”¨ä¼ å…¥çš„ lambda
    
    try:
        theta = np.linalg.inv(M + I_reg) @ (A.T @ Y)
    except np.linalg.LinAlgError:
        return None # å¥‡å¼‚çŸ©é˜µ

    # === 5. è¿˜åŸé¢„æµ‹å€¼ ===
    Y_hat = A @ theta
    
    if mode == 'log':
        s_pred = np.exp(Y_hat)
    elif mode == 'linear':
        s_pred = Y_hat
    elif mode == 'sqrt':
        s_pred = np.maximum(Y_hat, 0) ** 2
    elif mode == 'square':
        s_pred = np.sqrt(np.maximum(Y_hat, 0))
    
    # === 6. è®¡ç®—æŒ‡æ ‡ ===
    # IoU
    area_gt = s_gt ** 2
    area_pred = s_pred ** 2
    area_gt = np.maximum(area_gt, EPS)
    area_pred = np.maximum(area_pred, EPS)
    iou = np.minimum(area_gt, area_pred) / np.maximum(area_gt, area_pred)
    mean_iou = np.mean(iou)

    # MAPE
    diff_abs = np.abs(s_gt - s_pred)
    mape = diff_abs / (s_gt + EPS)
    mean_mape = np.mean(mape)

    return mean_iou, mean_mape

def process_file_grid_search(txt_path):
    """
    å•ä¸ªæ–‡ä»¶å¤„ç†å‡½æ•°ï¼šå¯¹è¯¥æ–‡ä»¶è·‘å®Œæ‰€æœ‰çš„å‚æ•°ç»„åˆ
    è¿”å›ï¼š{ (mode, lambda, norm): (iou, mape, count=1), ... }
    """
    bboxes, labels = parse_txt(txt_path)
    if len(bboxes) == 0: return None

    results = {}
    
    # ä¸‰å±‚å¾ªç¯éå†æ‰€æœ‰ç»„åˆ
    for mode in MODES:
        for ridge_lambda in LAMBDA_LIST:
            for norm_type in NORM_TYPES:
                
                res = solve_perspective(bboxes, labels, mode, ridge_lambda, norm_type)
                
                key = (mode, ridge_lambda, norm_type)
                if res is not None:
                    # è®°å½• (IoU, MAPE, æœ‰æ•ˆæ ·æœ¬æ•°)
                    results[key] = (res[0], res[1], len(bboxes))
                else:
                    results[key] = (0.0, 0.0, 0) # å¤±è´¥æ ‡è®°

    return results

def main():
    print(f"ğŸš€ å¯åŠ¨è¶…å‚æ•°è‡ªåŠ¨æœç´¢...")
    print(f"ğŸ“‚ æ•°æ®é›†æ ¹ç›®å½•: {DATASET_ROOT}")
    print(f"ğŸ¯ ç›®æ ‡å­é›†: {TARGET_SUBSETS}")
    print(f"âš™ï¸  æœç´¢ç©ºé—´: {len(MODES)} Modes x {len(LAMBDA_LIST)} Lambdas x {len(NORM_TYPES)} Norms = {len(MODES)*len(LAMBDA_LIST)*len(NORM_TYPES)} Combinations")
    
    # æ”¶é›†æ‰€æœ‰æ–‡ä»¶
    txt_files = []
    for subset in TARGET_SUBSETS:
        # é€‚é… DroneVehicle ç›®å½•ç»“æ„: subset/annfiles
        subset_path = os.path.join(DATASET_ROOT, subset, 'annfiles')
        if os.path.exists(subset_path):
            files = glob.glob(os.path.join(subset_path, '*.txt'))
            txt_files.extend(files)
            print(f"  - {subset}: æ‰¾åˆ° {len(files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        else:
            print(f"  - {subset}: è·¯å¾„ä¸å­˜åœ¨ {subset_path}")

    if len(txt_files) == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ ‡æ³¨æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return

    if MAX_FILES:
        txt_files = txt_files[:MAX_FILES]
        print(f"âš ï¸  ä»…ä½¿ç”¨å‰ {MAX_FILES} ä¸ªæ–‡ä»¶è¿›è¡Œå¿«é€ŸéªŒè¯")
    else:
        print(f"âœ… å°†è®¡ç®—æ‰€æœ‰ {len(txt_files)} ä¸ªæ–‡ä»¶")
    
    # åˆå§‹åŒ–å…¨å±€ç»Ÿè®¡å­—å…¸
    # global_stats[key] = {'total_iou': 0, 'total_mape': 0, 'total_samples': 0}
    global_stats = {}
    # åˆå§‹åŒ– keys
    for mode in MODES:
        for l in LAMBDA_LIST:
            for n in NORM_TYPES:
                global_stats[(mode, l, n)] = {'sum_iou': 0.0, 'sum_mape': 0.0, 'total_samples': 0}

    # å¤šè¿›ç¨‹å¤„ç†
    with multiprocessing.Pool(WORKER_NUM) as pool:
        for file_res in tqdm(pool.imap_unordered(process_file_grid_search, txt_files), total=len(txt_files)):
            if file_res is None: continue
            
            for key, val in file_res.items():
                mean_iou, mean_mape, n_objs = val
                if n_objs > 0:
                    # è¿˜åŸä¸º sumï¼Œä»¥ä¾¿å…¨å±€ç´¯åŠ 
                    global_stats[key]['sum_iou'] += mean_iou * n_objs
                    global_stats[key]['sum_mape'] += mean_mape * n_objs
                    global_stats[key]['total_samples'] += n_objs

    # æ±‡æ€»ç»“æœä¸º DataFrame
    rows = []
    for key, val in global_stats.items():
        mode, ridge_lambda, norm_type = key
        total = val['total_samples']
        if total > 0:
            final_iou = val['sum_iou'] / total
            final_mape = val['sum_mape'] / total
            rows.append({
                'Mode': mode,
                'Lambda': ridge_lambda,
                'Norm': norm_type,
                'IoU (%)': final_iou * 100,
                'MAPE (%)': final_mape * 100,
                'Samples': total
            })
    
    df = pd.DataFrame(rows)
    
    # æ’åºï¼šä¼˜å…ˆçœ‹ IoU (é™åº)ï¼Œå…¶æ¬¡çœ‹ MAPE (å‡åº)
    df = df.sort_values(by=['IoU (%)', 'MAPE (%)'], ascending=[False, True])
    
    print("\n" + "="*100)
    print("ğŸ† è¶…å‚æ•°æœç´¢æœ€ä½³ç»“æœ Top 20 (æŒ‰ IoU æ’åº)")
    print("="*100)
    pd.set_option('display.max_rows', 20)
    pd.set_option('display.width', 1000)
    print(df.head(20).to_string(index=False))
    
    # æ‰¾å‡ºæ¯ä¸ª Mode çš„æœ€ä½³é…ç½®
    print("\n" + "="*100)
    print("ğŸ¥‡ å„æ‹Ÿåˆæ¨¡å¼çš„æœ€ä½³é…ç½®")
    print("="*100)
    best_per_mode = df.loc[df.groupby('Mode')['IoU (%)'].idxmax()]
    print(best_per_mode.sort_values(by='IoU (%)', ascending=False).to_string(index=False))

    # ä¿å­˜å®Œæ•´ç»“æœ
    save_path = './select/dv.csv'
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    df.to_csv(save_path, index=False)
    print(f"\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜è‡³: {save_path}")

if __name__ == '__main__':
    multiprocessing.set_start_method('fork', force=True)
    main()
